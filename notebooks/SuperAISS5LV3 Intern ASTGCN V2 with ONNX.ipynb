{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDjoDg42kMGv"
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 channel Terms of Service accepted\n",
      "Channels:\n",
      " - pyg\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: c:\\Users\\patar\\miniconda3\\envs\\superai-intern\n",
      "\n",
      "  added / updated specs:\n",
      "    - pyg\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    colorama-0.4.6             |  py310haa95532_0          32 KB\n",
      "    packaging-24.2             |  py310haa95532_0         175 KB\n",
      "    platformdirs-4.3.7         |  py310haa95532_0          37 KB\n",
      "    psutil-5.9.0               |  py310h827c3e9_1         388 KB\n",
      "    six-1.17.0                 |  py310haa95532_0          32 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         665 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  aiohappyeyeballs   pkgs/main/win-64::aiohappyeyeballs-2.4.4-py310haa95532_0 \n",
      "  aiohttp            pkgs/main/win-64::aiohttp-3.11.10-py310h827c3e9_0 \n",
      "  aiosignal          pkgs/main/noarch::aiosignal-1.2.0-pyhd3eb1b0_0 \n",
      "  async-timeout      pkgs/main/win-64::async-timeout-5.0.1-py310haa95532_0 \n",
      "  attrs              pkgs/main/win-64::attrs-24.3.0-py310haa95532_0 \n",
      "  blas               pkgs/main/win-64::blas-1.0-mkl \n",
      "  brotlicffi         pkgs/main/win-64::brotlicffi-1.0.9.2-py310h5da7b33_1 \n",
      "  certifi            pkgs/main/win-64::certifi-2025.7.14-py310haa95532_0 \n",
      "  cffi               pkgs/main/win-64::cffi-1.17.1-py310h827c3e9_1 \n",
      "  charset-normalizer pkgs/main/noarch::charset-normalizer-3.3.2-pyhd3eb1b0_0 \n",
      "  colorama           pkgs/main/win-64::colorama-0.4.6-py310haa95532_0 \n",
      "  cudatoolkit        pkgs/main/win-64::cudatoolkit-11.3.1-h59b6b97_2 \n",
      "  frozenlist         pkgs/main/win-64::frozenlist-1.5.0-py310h827c3e9_0 \n",
      "  fsspec             pkgs/main/win-64::fsspec-2025.5.1-py310hbc747e5_0 \n",
      "  future             pkgs/main/win-64::future-1.0.0-py310haa95532_0 \n",
      "  icc_rt             pkgs/main/win-64::icc_rt-2022.1.0-h6049295_2 \n",
      "  idna               pkgs/main/win-64::idna-3.7-py310haa95532_0 \n",
      "  intel-openmp       pkgs/main/win-64::intel-openmp-2021.4.0-haa95532_3556 \n",
      "  jinja2             pkgs/main/win-64::jinja2-3.1.6-py310haa95532_0 \n",
      "  joblib             pkgs/main/win-64::joblib-1.4.2-py310haa95532_0 \n",
      "  libuv              pkgs/main/win-64::libuv-1.48.0-h827c3e9_0 \n",
      "  markupsafe         pkgs/main/win-64::markupsafe-3.0.2-py310h827c3e9_0 \n",
      "  mkl                pkgs/main/win-64::mkl-2021.4.0-haa95532_640 \n",
      "  mkl-service        pkgs/main/win-64::mkl-service-2.4.0-py310h2bbff1b_0 \n",
      "  mkl_fft            pkgs/main/win-64::mkl_fft-1.3.1-py310ha0764ea_0 \n",
      "  mkl_random         pkgs/main/win-64::mkl_random-1.2.2-py310h4ed8f06_0 \n",
      "  multidict          pkgs/main/win-64::multidict-6.1.0-py310h827c3e9_0 \n",
      "  ninja              pkgs/main/win-64::ninja-1.12.1-haa95532_0 \n",
      "  ninja-base         pkgs/main/win-64::ninja-base-1.12.1-h4157e71_0 \n",
      "  numpy              pkgs/main/win-64::numpy-1.24.3-py310hdc03b94_0 \n",
      "  numpy-base         pkgs/main/win-64::numpy-base-1.24.3-py310h3caf3d7_0 \n",
      "  packaging          pkgs/main/win-64::packaging-24.2-py310haa95532_0 \n",
      "  platformdirs       pkgs/main/win-64::platformdirs-4.3.7-py310haa95532_0 \n",
      "  pooch              pkgs/main/win-64::pooch-1.8.2-py310haa95532_0 \n",
      "  propcache          pkgs/main/win-64::propcache-0.3.1-py310h827c3e9_0 \n",
      "  psutil             pkgs/main/win-64::psutil-5.9.0-py310h827c3e9_1 \n",
      "  pycparser          pkgs/main/noarch::pycparser-2.21-pyhd3eb1b0_0 \n",
      "  pyg                pyg/win-64::pyg-2.5.2-py310_torch_1.12.0_cu113 \n",
      "  pyparsing          pkgs/main/win-64::pyparsing-3.2.0-py310haa95532_0 \n",
      "  pysocks            pkgs/main/win-64::pysocks-1.7.1-py310haa95532_0 \n",
      "  pytorch            pkgs/main/win-64::pytorch-1.12.1-cpu_py310h5e1f01c_1 \n",
      "  pyyaml             pkgs/main/win-64::pyyaml-6.0.2-py310h827c3e9_0 \n",
      "  requests           pkgs/main/win-64::requests-2.32.4-py310haa95532_0 \n",
      "  scikit-learn       pkgs/main/win-64::scikit-learn-1.7.1-py310h3fbe716_0 \n",
      "  scipy              pkgs/main/win-64::scipy-1.10.1-py310hb9afe5d_0 \n",
      "  six                pkgs/main/win-64::six-1.17.0-py310haa95532_0 \n",
      "  threadpoolctl      pkgs/main/win-64::threadpoolctl-3.5.0-py310h9909e9c_0 \n",
      "  tqdm               pkgs/main/win-64::tqdm-4.67.1-py310h9909e9c_0 \n",
      "  typing-extensions  pkgs/main/win-64::typing-extensions-4.12.2-py310haa95532_0 \n",
      "  typing_extensions  pkgs/main/win-64::typing_extensions-4.12.2-py310haa95532_0 \n",
      "  urllib3            pkgs/main/win-64::urllib3-2.5.0-py310haa95532_0 \n",
      "  win_inet_pton      pkgs/main/win-64::win_inet_pton-1.1.0-py310haa95532_0 \n",
      "  yaml               pkgs/main/win-64::yaml-0.2.5-he774522_0 \n",
      "  yarl               pkgs/main/win-64::yarl-1.18.0-py310h827c3e9_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "psutil-5.9.0         | 388 KB    |            |   0% \n",
      "\n",
      "packaging-24.2       | 175 KB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "platformdirs-4.3.7   | 37 KB     |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 32 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "six-1.17.0           | 32 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "six-1.17.0           | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "platformdirs-4.3.7   | 37 KB     | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "six-1.17.0           | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "six-1.17.0           | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 32 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "platformdirs-4.3.7   | 37 KB     | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "platformdirs-4.3.7   | 37 KB     | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "packaging-24.2       | 175 KB    | 9          |   9% \u001b[A\n",
      "psutil-5.9.0         | 388 KB    | 4          |   4% \n",
      "\n",
      "packaging-24.2       | 175 KB    | #8         |  18% \u001b[A\n",
      "psutil-5.9.0         | 388 KB    | #6         |  16% \n",
      "\n",
      "packaging-24.2       | 175 KB    | ####5      |  46% \u001b[A\n",
      "\n",
      "packaging-24.2       | 175 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "packaging-24.2       | 175 KB    | ########## | 100% \u001b[A\n",
      "\n",
      "packaging-24.2       | 175 KB    | ########## | 100% \u001b[A\n",
      "psutil-5.9.0         | 388 KB    | ####5      |  45% \n",
      "psutil-5.9.0         | 388 KB    | #######8   |  78% \n",
      "psutil-5.9.0         | 388 KB    | ########## | 100% \n",
      "psutil-5.9.0         | 388 KB    | ########## | 100% \n",
      "psutil-5.9.0         | 388 KB    | ########## | 100% \n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install pyg -c pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.__version__)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.version.cuda)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.7.0+cu128.html\n",
      "Collecting pyg_lib\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/pyg_lib-0.4.0%2Bpt27cu128-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 3.7/3.7 MB 73.7 MB/s eta 0:00:00\n",
      "Collecting torch_scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/torch_scatter-2.1.2%2Bpt27cu128-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.8/3.6 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.8/3.6 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.6/3.6 MB 6.3 MB/s eta 0:00:00\n",
      "Collecting torch_sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/torch_sparse-0.6.18%2Bpt27cu128-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     -------------- ------------------------- 0.8/2.1 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.8/2.1 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting torch_cluster\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/torch_cluster-1.6.3%2Bpt27cu128-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.6/1.6 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting torch_spline_conv\n",
      "  Downloading https://data.pyg.org/whl/torch-2.7.0%2Bcu128/torch_spline_conv-1.2.2%2Bpt27cu128-cp310-cp310-win_amd64.whl (603 kB)\n",
      "     ---------------------------------------- 0.0/603.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/603.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/603.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/603.3 kB ? eta -:--:--\n",
      "     --------------------------------- ---- 524.3/603.3 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 603.3/603.3 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch_sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from scipy->torch_sparse) (1.24.3)\n",
      "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
      "\n",
      "   -------- ------------------------------- 1/5 [torch_scatter]\n",
      "   ------------------------ --------------- 3/5 [torch_sparse]\n",
      "   -------------------------------- ------- 4/5 [torch_cluster]\n",
      "   ---------------------------------------- 5/5 [torch_cluster]\n",
      "\n",
      "Successfully installed pyg_lib-0.4.0+pt27cu128 torch_cluster-1.6.3+pt27cu128 torch_scatter-2.1.2+pt27cu128 torch_sparse-0.6.18+pt27cu128 torch_spline_conv-1.2.2+pt27cu128\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.7.0+cu128.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: Could not find module 'C:\\Users\\patar\\miniconda3\\envs\\superai-intern\\Lib\\site-packages\\libpyg.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "c:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "c:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\typing.py:83: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "c:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\typing.py:99: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(\n",
      "c:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: [WinError 127] The specified procedure could not be found\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric_temporal\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA available:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric_temporal\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric_temporal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric_temporal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric_temporal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric_temporal\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhetero\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric_temporal\\nn\\recurrent\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgconv_gru\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GConvGRU\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgconv_lstm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GConvLSTM\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlrgcn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LRGCN\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric_temporal\\nn\\recurrent\\gconv_gru.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChebConv\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mGConvGRU\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"An implementation of the Chebyshev Graph Convolutional Gated Recurrent Unit\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Cell. For details see this paper: `\"Structured Sequence Modeling with Graph\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Convolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m            an additive bias. (default: :obj:`True`)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\datasets\\__init__.py:101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msbm_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomPartitionGraphDataset\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixhop_synthetic_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MixHopSyntheticDataset\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainer_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplainerDataset\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfection_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InfectionDataset\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mba2motif_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BA2MotifDataset\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\datasets\\explainer_dataset.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphGenerator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmotif_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MotifGenerator\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Explanation\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mExplainerDataset\u001b[39;00m(InMemoryDataset):\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Generates a synthetic dataset for evaluating explainabilty algorithms,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    as described in the `\"GNNExplainer: Generating Explanations for Graph\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Neural Networks\" <https://arxiv.org/abs/1903.03894>`__ paper.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m            (default: :obj:`None`)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\explain\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplainerConfig, ModelConfig, ThresholdConfig\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplanation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Explanation, HeteroExplanation\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Explainer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\explain\\algorithm\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExplainerAlgorithm\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdummy_explainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DummyExplainer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn_explainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GNNExplainer\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\explain\\algorithm\\base.py:14\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Explanation, HeteroExplanation\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ExplainerConfig,\n\u001b[0;32m     11\u001b[0m     ModelConfig,\n\u001b[0;32m     12\u001b[0m     ModelReturnType,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EdgeType, NodeType\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m k_hop_subgraph\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\nn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_parallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_hetero_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_hetero\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_hetero_with_bases_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_hetero_with_bases\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_fixed_size_transformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_fixed_size\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PositionalEncoding, TemporalEncoding\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_with_bases_transformer.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module, Parameter\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdense\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Transformer\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\nn\\conv\\__init__.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcugraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msage_conv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CuGraphSAGEConv\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_conv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphConv\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgravnet_conv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GravNetConv\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgated_graph_conv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GatedGraphConv\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mres_gated_graph_conv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ResGatedGraphConv\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_geometric\\nn\\conv\\gravnet_conv.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OptTensor, PairOptTensor, PairTensor\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_cluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m knn\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m     knn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch_cluster\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages\\torch\\_ops.py:255\u001b[0m, in \u001b[0;36mload_library\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not find kernel for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at dispatch key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m _higher_order_ops: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHigherOrderOperator\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    252\u001b[0m _HIGHER_ORDER_OP_DEFAULT_FALLTHROUGH_DISPATCH_KEYS \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    253\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mPythonDispatcher,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mPythonTLSSnapshot,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mADInplaceOrView,\n\u001b[0;32m    256\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mBackendSelect,\n\u001b[0;32m    257\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mAutocastCPU,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     DispatchKey\u001b[38;5;241m.\u001b[39mAutocastCUDA,  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ]\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mHigherOrderOperator\u001b[39;00m(OperatorBase, abc\u001b[38;5;241m.\u001b[39mABC):\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# The HigherOrderOperator will appear as torch.ops.higher_order.{name}\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# If you're creating a new HigherOrderOperator, please do not change the\u001b[39;00m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;66;03m# default. Adding operators to the global torch.ops namespace is a bad\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# practice due to name collisions.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[38;5;241m*\u001b[39m, cacheable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\patar\\miniconda3\\envs\\superai-intern\\lib\\ctypes\\__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric_temporal\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-16T16:31:30.493483Z",
     "iopub.status.busy": "2025-07-16T16:31:30.493294Z",
     "iopub.status.idle": "2025-07-16T17:24:33.326345Z",
     "shell.execute_reply": "2025-07-16T17:24:33.325386Z",
     "shell.execute_reply.started": "2025-07-16T16:31:30.493468Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (1.7.1)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.1-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (1.24.3)\n",
      "Collecting torchview\n",
      "  Using cached torchview-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting visualtorch\n",
      "  Using cached visualtorch-0.2.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting gdown\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting torch-geometric-temporal\n",
      "  Using cached torch_geometric_temporal-0.56.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: torch-cluster in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (1.6.3+pt27cu128)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\patar\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting graphviz (from torchview)\n",
      "  Using cached graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pillow>=10.0.0 (from visualtorch)\n",
      "  Using cached pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting aggdraw>=1.3.11 (from visualtorch)\n",
      "  Using cached aggdraw-1.3.19-cp310-cp310-win_amd64.whl.metadata (673 bytes)\n",
      "Collecting torch>=2.0.0 (from visualtorch)\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from gdown) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from gdown) (4.67.1)\n",
      "Collecting decorator==4.4.2 (from torch-geometric-temporal)\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting cython (from torch-geometric-temporal)\n",
      "  Using cached cython-3.1.2-cp310-cp310-win_amd64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: torch-sparse in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch-geometric-temporal) (0.6.18+pt27cu128)\n",
      "Requirement already satisfied: torch-scatter in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch-geometric-temporal) (2.1.2+pt27cu128)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch-geometric-temporal) (2.5.2)\n",
      "Collecting networkx (from torch-geometric-temporal)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patar\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\patar\\appdata\\roaming\\python\\python310\\site-packages (from torch>=2.0.0->visualtorch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->visualtorch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch>=2.0.0->visualtorch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch>=2.0.0->visualtorch) (2025.5.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->visualtorch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from jinja2->torch>=2.0.0->visualtorch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from requests[socks]->gdown) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from requests[socks]->gdown) (2025.7.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (3.11.10)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (3.2.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\patar\\appdata\\roaming\\python\\python310\\site-packages (from torch-geometric->torch-geometric-temporal) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.18.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\patar\\miniconda3\\envs\\superai-intern\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (5.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\patar\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Using cached pandas-2.3.1-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "Using cached torchview-0.2.7-py3-none-any.whl (26 kB)\n",
      "Using cached visualtorch-0.2.4-py3-none-any.whl (19 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached torch_geometric_temporal-0.56.2-py3-none-any.whl (102 kB)\n",
      "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Using cached aggdraw-1.3.19-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Using cached pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached cython-3.1.2-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: pytz, mpmath, tzdata, sympy, soupsieve, pillow, networkx, graphviz, filelock, decorator, cython, aggdraw, torchview, torch, pandas, beautifulsoup4, visualtorch, gdown, torch-geometric-temporal\n",
      "\n",
      "   ----------------------------------------  0/19 [pytz]\n",
      "   ----------------------------------------  0/19 [pytz]\n",
      "   -- -------------------------------------  1/19 [mpmath]\n",
      "   -- -------------------------------------  1/19 [mpmath]\n",
      "   -- -------------------------------------  1/19 [mpmath]\n",
      "   -- -------------------------------------  1/19 [mpmath]\n",
      "   ---- -----------------------------------  2/19 [tzdata]\n",
      "   ---- -----------------------------------  2/19 [tzdata]\n",
      "   ---- -----------------------------------  2/19 [tzdata]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ------ ---------------------------------  3/19 [sympy]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ---------- -----------------------------  5/19 [pillow]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ------------ ---------------------------  6/19 [networkx]\n",
      "   ---------------- -----------------------  8/19 [filelock]\n",
      "  Attempting uninstall: decorator\n",
      "   ---------------- -----------------------  8/19 [filelock]\n",
      "    Found existing installation: decorator 5.2.1\n",
      "   ---------------- -----------------------  8/19 [filelock]\n",
      "    Uninstalling decorator-5.2.1:\n",
      "   ---------------- -----------------------  8/19 [filelock]\n",
      "   ------------------ ---------------------  9/19 [decorator]\n",
      "      Successfully uninstalled decorator-5.2.1\n",
      "   ------------------ ---------------------  9/19 [decorator]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "  Attempting uninstall: torch\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "    Found existing installation: torch 1.12.1\n",
      "   --------------------- ------------------ 10/19 [cython]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "    Uninstalling torch-1.12.1:\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   --------------------------- ------------ 13/19 [torch]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ----------------------------- ---------- 14/19 [pandas]\n",
      "   ------------------------------- -------- 15/19 [beautifulsoup4]\n",
      "   ------------------------------- -------- 15/19 [beautifulsoup4]\n",
      "   ----------------------------------- ---- 17/19 [gdown]\n",
      "   ------------------------------------- -- 18/19 [torch-geometric-temporal]\n",
      "   ---------------------------------------- 19/19 [torch-geometric-temporal]\n",
      "\n",
      "Successfully installed aggdraw-1.3.19 beautifulsoup4-4.13.4 cython-3.1.2 decorator-4.4.2 filelock-3.18.0 gdown-5.2.0 graphviz-0.21 mpmath-1.3.0 networkx-3.4.2 pandas-2.3.1 pillow-11.3.0 pytz-2025.2 soupsieve-2.7 sympy-1.14.0 torch-2.7.1 torch-geometric-temporal-0.56.2 torchview-0.2.7 tzdata-2025.2 visualtorch-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn pandas numpy torchview visualtorch gdown torch-geometric-temporal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-16T09:03:59.702807Z",
     "iopub.status.busy": "2025-07-16T09:03:59.702502Z",
     "iopub.status.idle": "2025-07-16T09:04:12.959173Z",
     "shell.execute_reply": "2025-07-16T09:04:12.958147Z",
     "shell.execute_reply.started": "2025-07-16T09:03:59.702781Z"
    },
    "id": "Y9ekDThljjj0",
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder 1KjgtXYS3NaIN6tik_daJWOl63IgzGso7 Data_\n",
      "Processing file 1KMDUW5SuAI6kFWNPkfWbwDgcTSSvYxT8 -Demand---01-2024.xlsx\n",
      "Processing file 1hdn9FIx3p2tRGlTKHJDcPidkSPPtXoOx -Demand---02-2024.xlsx\n",
      "Processing file 10XGBjCursyMvv8EBxKO3i_2OOP9aRHP2 -Demand---03-2024.xlsx\n",
      "Processing file 1D09dkdAj-a_bCZixA2Fl2XS3GFWrllJD -Demand---04-2024.xlsx\n",
      "Processing file 17yXlMWcwocV7LYA5ZqI7Mfbt9U2pQHS- -Demand---05-2024.xlsx\n",
      "Processing file 1pNPnr9FucqI_j3YLWLyoLNnvvbzDQ3Rp -Demand---06-2024.xlsx\n",
      "Processing file 1ZqvUMcV1KusK_3P5cgODBvPEuFtX3CRK -Demand---07-2024.xlsx\n",
      "Processing file 1ApbincXLdZCwYAk4VWnZf9gV6cjUMmlW -Demand---08-2024.xlsx\n",
      "Processing file 1-r7wosGYXQZhRPuU9iMyI-eK41u1vEjT -Demand---09-2024.xlsx\n",
      "Processing file 1IzPmFYeGAlRfh7D6YLdmGnWcY0dk6gT4 -Demand---10-2024.xlsx\n",
      "Processing file 1SB4_y7HwgY0teT2X1wv0HOPr3-eicRtK -Demand---11-2024.xlsx\n",
      "Processing file 1uJkDVZMpQe3Ta2jVVyI78YXwOoFQ3DOZ -Demand---12-2023.xlsx\n",
      "Retrieving folder 18jHYsTY6jycKhOJD94MW3SXjoDiwjnCc Data_ 9\n",
      "Processing file 1p5SpyFtAtk-FX_dd0DEPXsopfGJavker -Demand--9-01-2024.xlsx\n",
      "Processing file 1TpoAyqP1zGbb9cxi2hsoZTiFKX3MkxLP -Demand--9-02-2024.xlsx\n",
      "Processing file 12CVOQWTfgBJ7CMimiPsI8-H-VbKrF9fg -Demand--9-03-2024.xlsx\n",
      "Processing file 1eKf4oYaMylY90vWTAGTBFotOcp0bA_nZ -Demand--9-04-2024.xlsx\n",
      "Processing file 15uy45zg_JacL8lcfYPWSqtZ3jtOb8lgu -Demand--9-05-2024.xlsx\n",
      "Processing file 1Vaiou5E3ZVrIEa5etL4p0fMMAfknhnGL -Demand--9-06-2024.xlsx\n",
      "Processing file 10s5mmIUpazVKxJYM3-eO0YEYgii3sGIx -Demand--9-07-2024.xlsx\n",
      "Processing file 1JHVpDqwYYiDCn8tA-ldoXOrRfVQNg4lA -Demand--9-08-2024.xlsx\n",
      "Processing file 1yNwJgHxR_HO6eyb8NUB0kMsw8DPOCcI4 -Demand--9-09-2024.xlsx\n",
      "Processing file 1N41graZU5FOy_X2rw5LXwpnD6y0lbika -Demand--9-10-2024.xlsx\n",
      "Processing file 1-l1GwQZzoRAZDCQpG9GYwBFNDsGMYUUl -Demand--9-11-2024.xlsx\n",
      "Processing file 1IPIfknzUhQiYKZGM_hJA66JOXDDwA8RB -Demand--9-12-2023.xlsx\n",
      "Retrieving folder 1dlpcqo-bIRWIbP3PEWgQi3Fs40RuIMa5 Data_4\n",
      "Processing file 1wu-KZmFYLY2aQd3Ms9Y7XT0S-4nDG2Ys -Demand---4-01-2024.xlsx\n",
      "Processing file 1p6WMenk_p-IhPYvlMVjjGRBbkgnPJrwX -Demand---4-02-2024.xlsx\n",
      "Processing file 16ytjIJ2OsapaYEU8A7zj7k4Bt487JuDf -Demand---4-03-2024.xlsx\n",
      "Processing file 1hOXBBLm-oiIIwIr6ckluS_y1TQPDSphD -Demand---4-04-2024.xlsx\n",
      "Processing file 1QTTycNIW3IDHAGyn9XhUOB6dXVRGXyGm -Demand---4-05-2024.xlsx\n",
      "Processing file 13GrHBmYyxU8w6N4X8MeiKN5ZYBZ4m4GF -Demand---4-06-2024.xlsx\n",
      "Processing file 1jpXvAa_INiqvbsDPRZS3-7CUUHm3w2ct -Demand---4-07-2024.xlsx\n",
      "Processing file 1r5p_A1YmHg56GHWBK7ovuoQeR59LG61Q -Demand---4-08-2024.xlsx\n",
      "Processing file 11YJ0g2u6aAsoFe3OfWk3Q9Jxs_siY406 -Demand---4-09-2024.xlsx\n",
      "Processing file 1Oj2vp0wH7JpIiB_Sf7oHIYjdEtFzQHB9 -Demand---4-10-2024.xlsx\n",
      "Processing file 1mJCz8Z15e5uA-o7COdjfRrAnCA5xRL4P -Demand---4-11-2024.xlsx\n",
      "Retrieving folder 1trvUBpA7rlIwZKsFT_jM8K9-XQsnnm6L Data_\n",
      "Processing file 1evDuJ7OpWKdKIwr0R2k8grAycLI1WQwP -Demand---01-2024.xlsx\n",
      "Processing file 1NKn1ROiM7QSBK15dOn--oCYWWmUkSxN6 -Demand---02-2024.xlsx\n",
      "Processing file 15JN-BsvECrI6Pux5DOKZqNhAkosKmmQh -Demand---03-2024.xlsx\n",
      "Processing file 1sf_qQ_boL0YBW79VH4G66yRKDWAnn4Nk -Demand---04-2024.xlsx\n",
      "Processing file 1ii1fFuhtdpLdtkPUIx95J7K5YE4gLmwc -Demand---05-2024.xlsx\n",
      "Processing file 1MiMtCvB1QqAfGzFUUEAuRT7TP5Eq8dPw -Demand---06-2024.xlsx\n",
      "Processing file 1GQoWLINz4yLZm7MAkzptupQytZeeXais -Demand---07-2024.xlsx\n",
      "Processing file 1MfAIg9JF08eAoZYvgG6oYGnAgvxchqgt -Demand---08-2024.xlsx\n",
      "Processing file 1_W-TTGsPII9FpaieqFWF4pyRHMWN-3C6 -Demand---09-2024.xlsx\n",
      "Processing file 1X45InFbJlO0gQRDfmkYlyZqs3lmRxtW7 -Demand---10-2024.xlsx\n",
      "Processing file 1eTeNfJ-c8y36QCspeljRikeK4Uz-yjVd -Demand---11-2024.xlsx\n",
      "Processing file 1RUZ2akVj03nuKaXAaQcpf44ozDRSOk28 -Demand---12-2023.xlsx\n",
      "Retrieving folder 1CzmC8coVMu96Eww5Oc3V5eq567EP8-sQ Data_\n",
      "Processing file 1f1FdeiIbcvfq3BSntDkPXLe9OpgZM8Qt -Demand---01-2024.xlsx\n",
      "Processing file 1mBPQLjo6nHgESrcjGdtUC4Z8X48Qt8SR -Demand---02-2024.xlsx\n",
      "Processing file 1dQvVRFxbLjklFxWFG24EzYm4ckoWfvKC -Demand---03-2024.xlsx\n",
      "Processing file 1IxH87LwFYVD4UqbpN4Hn0iZ5nsKDGC4f -Demand---04-2024.xlsx\n",
      "Processing file 1n05RkkhMQZaAMBpnAXbWXNSH24KkUG0e -Demand---05-2024.xlsx\n",
      "Processing file 1yBPEvHZdE9KoDOOqglOKae3Hc6IUtoiR -Demand---06-2024.xlsx\n",
      "Processing file 1NJ-iAAVOoGv7xx71iQLGMEMpBsfeQ48_ -Demand---07-2024.xlsx\n",
      "Processing file 1oFzgGtIqvcnJS-F97m6LaN3Qz5hTj6d2 -Demand---08-2024.xlsx\n",
      "Processing file 1iy8MB7L6cybJQAFvrpCOlI7jmQUCU11d -Demand---09-2024.xlsx\n",
      "Processing file 1YTXYEbpDKkqgjtNcJiHtm81GgyzKWxT6 -Demand---10-2024.xlsx\n",
      "Processing file 1X0o1GWnTt6u5Pj-sDlaNurSNg5kqEE8v -Demand---11-2024.xlsx\n",
      "Processing file 1NsfBsiXuTU1RovfUK0qiIdrsgnBa61T3 -Demand---12-2023.xlsx\n",
      "Retrieving folder 1XEGVTGm8JRYdJXSUteYJ--12JfqBdZcR Data_\n",
      "Processing file 1CPfb7PUOgjVWtcHrkQelGsdBRNq2Ks9t -Demand---01-2024.xlsx\n",
      "Processing file 1lnZY1HzGuDujmNIu9cvxnD8Wse5Gizjh -Demand---02-2024.xlsx\n",
      "Processing file 1UXzCiuifVR3GcBQ1Wpc2OYwGmrOUxIJ- -Demand---03-2024.xlsx\n",
      "Processing file 1qQtZKWTxTDOTLI7-3o5xckUR06yOVDwE -Demand---04-2024.xlsx\n",
      "Processing file 1VyBJVugdCUCoz3ENg6GZC_hCiBbrDvD6 -Demand---05-2024.xlsx\n",
      "Processing file 187xYRYUgMAFAWcWJb77R1fc-Tl2YtcP8 -Demand---06-2024.xlsx\n",
      "Processing file 1J4EiGlIE8ehdJQMeHlYZdwDyGVjZqw9J -Demand---07-2024.xlsx\n",
      "Processing file 1aA3tLylhJkC86nlTCuIQUtaq3KWK2e-m -Demand---08-2024.xlsx\n",
      "Processing file 1OZjJ_yV5R6mJ4FTMu_BwayI3LMZ-WlxZ -Demand---09-2024.xlsx\n",
      "Processing file 1ak97Cajq-cUVgTvr2IxRUCBPMeFH05Nq -Demand---10-2024.xlsx\n",
      "Processing file 1RpHyI1hSq58LEwh1ijnAgR1JR4qGamKC -Demand---11-2024.xlsx\n",
      "Processing file 1sbSiynPi7ncwHIgmtQy-YnrQ8JisoNsv -Demand---12-2023.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n",
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KMDUW5SuAI6kFWNPkfWbwDgcTSSvYxT8\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.9k [00:00<?, ?B/s]\n",
      "100%|| 21.9k/21.9k [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hdn9FIx3p2tRGlTKHJDcPidkSPPtXoOx\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.2k [00:00<?, ?B/s]\n",
      "100%|| 20.2k/20.2k [00:00<00:00, 1.08MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=10XGBjCursyMvv8EBxKO3i_2OOP9aRHP2\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.9k [00:00<?, ?B/s]\n",
      "100%|| 21.9k/21.9k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1D09dkdAj-a_bCZixA2Fl2XS3GFWrllJD\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.5k [00:00<?, ?B/s]\n",
      "100%|| 20.5k/20.5k [00:00<00:00, 915kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17yXlMWcwocV7LYA5ZqI7Mfbt9U2pQHS-\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.6k [00:00<?, ?B/s]\n",
      "100%|| 21.6k/21.6k [00:00<00:00, 1.11MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1pNPnr9FucqI_j3YLWLyoLNnvvbzDQ3Rp\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---06-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.3k [00:00<?, ?B/s]\n",
      "100%|| 21.3k/21.3k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ZqvUMcV1KusK_3P5cgODBvPEuFtX3CRK\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---07-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.2k [00:00<?, ?B/s]\n",
      "100%|| 21.2k/21.2k [00:00<00:00, 999kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ApbincXLdZCwYAk4VWnZf9gV6cjUMmlW\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---08-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.8k [00:00<?, ?B/s]\n",
      "100%|| 21.8k/21.8k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-r7wosGYXQZhRPuU9iMyI-eK41u1vEjT\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---09-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.4k [00:00<?, ?B/s]\n",
      "100%|| 21.4k/21.4k [00:00<00:00, 982kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IzPmFYeGAlRfh7D6YLdmGnWcY0dk6gT4\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---10-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/50.7k [00:00<?, ?B/s]\n",
      "100%|| 50.7k/50.7k [00:00<00:00, 1.23MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SB4_y7HwgY0teT2X1wv0HOPr3-eicRtK\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---11-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.9k [00:00<?, ?B/s]\n",
      "100%|| 19.9k/19.9k [00:00<00:00, 984kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1uJkDVZMpQe3Ta2jVVyI78YXwOoFQ3DOZ\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---12-2023.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.0k [00:00<?, ?B/s]\n",
      "100%|| 21.0k/21.0k [00:00<00:00, 1.05MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1p5SpyFtAtk-FX_dd0DEPXsopfGJavker\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/23.0k [00:00<?, ?B/s]\n",
      "100%|| 23.0k/23.0k [00:00<00:00, 1.07MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1TpoAyqP1zGbb9cxi2hsoZTiFKX3MkxLP\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.2k [00:00<?, ?B/s]\n",
      "100%|| 21.2k/21.2k [00:00<00:00, 965kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12CVOQWTfgBJ7CMimiPsI8-H-VbKrF9fg\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/23.3k [00:00<?, ?B/s]\n",
      "100%|| 23.3k/23.3k [00:00<00:00, 1.04MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1eKf4oYaMylY90vWTAGTBFotOcp0bA_nZ\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.2k [00:00<?, ?B/s]\n",
      "100%|| 22.2k/22.2k [00:00<00:00, 1.09MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15uy45zg_JacL8lcfYPWSqtZ3jtOb8lgu\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/23.2k [00:00<?, ?B/s]\n",
      "100%|| 23.2k/23.2k [00:00<00:00, 955kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Vaiou5E3ZVrIEa5etL4p0fMMAfknhnGL\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-06-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.6k [00:00<?, ?B/s]\n",
      "100%|| 22.6k/22.6k [00:00<00:00, 984kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=10s5mmIUpazVKxJYM3-eO0YEYgii3sGIx\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-07-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.5k [00:00<?, ?B/s]\n",
      "100%|| 22.5k/22.5k [00:00<00:00, 1.24MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JHVpDqwYYiDCn8tA-ldoXOrRfVQNg4lA\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-08-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.9k [00:00<?, ?B/s]\n",
      "100%|| 22.9k/22.9k [00:00<00:00, 966kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yNwJgHxR_HO6eyb8NUB0kMsw8DPOCcI4\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-09-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.5k [00:00<?, ?B/s]\n",
      "100%|| 22.5k/22.5k [00:00<00:00, 1.13MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1N41graZU5FOy_X2rw5LXwpnD6y0lbika\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-10-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/53.5k [00:00<?, ?B/s]\n",
      "100%|| 53.5k/53.5k [00:00<00:00, 1.30MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-l1GwQZzoRAZDCQpG9GYwBFNDsGMYUUl\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-11-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.7k [00:00<?, ?B/s]\n",
      "100%|| 20.7k/20.7k [00:00<00:00, 1.13MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IPIfknzUhQiYKZGM_hJA66JOXDDwA8RB\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_ 9\\-Demand--9-12-2023.xlsx\n",
      "\n",
      "  0%|          | 0.00/22.7k [00:00<?, ?B/s]\n",
      "100%|| 22.7k/22.7k [00:00<00:00, 1.05MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1wu-KZmFYLY2aQd3Ms9Y7XT0S-4nDG2Ys\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.05MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1p6WMenk_p-IhPYvlMVjjGRBbkgnPJrwX\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.2k [00:00<?, ?B/s]\n",
      "100%|| 19.2k/19.2k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16ytjIJ2OsapaYEU8A7zj7k4Bt487JuDf\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.05MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hOXBBLm-oiIIwIr6ckluS_y1TQPDSphD\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.4k [00:00<?, ?B/s]\n",
      "100%|| 19.4k/19.4k [00:00<00:00, 1.19MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QTTycNIW3IDHAGyn9XhUOB6dXVRGXyGm\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.7k [00:00<?, ?B/s]\n",
      "100%|| 20.7k/20.7k [00:00<00:00, 938kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13GrHBmYyxU8w6N4X8MeiKN5ZYBZ4m4GF\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-06-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.1k [00:00<?, ?B/s]\n",
      "100%|| 20.1k/20.1k [00:00<00:00, 1.06MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1jpXvAa_INiqvbsDPRZS3-7CUUHm3w2ct\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-07-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1r5p_A1YmHg56GHWBK7ovuoQeR59LG61Q\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-08-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.6k [00:00<?, ?B/s]\n",
      "100%|| 20.6k/20.6k [00:00<00:00, 1.03MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11YJ0g2u6aAsoFe3OfWk3Q9Jxs_siY406\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-09-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.1k [00:00<?, ?B/s]\n",
      "100%|| 20.1k/20.1k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Oj2vp0wH7JpIiB_Sf7oHIYjdEtFzQHB9\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-10-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/49.1k [00:00<?, ?B/s]\n",
      "100%|| 49.1k/49.1k [00:00<00:00, 1.23MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mJCz8Z15e5uA-o7COdjfRrAnCA5xRL4P\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_4\\-Demand---4-11-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.1k [00:00<?, ?B/s]\n",
      "100%|| 19.1k/19.1k [00:00<00:00, 998kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1evDuJ7OpWKdKIwr0R2k8grAycLI1WQwP\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.8k [00:00<?, ?B/s]\n",
      "100%|| 20.8k/20.8k [00:00<00:00, 1.04MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NKn1ROiM7QSBK15dOn--oCYWWmUkSxN6\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.2k [00:00<?, ?B/s]\n",
      "100%|| 19.2k/19.2k [00:00<00:00, 852kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15JN-BsvECrI6Pux5DOKZqNhAkosKmmQh\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.8k [00:00<?, ?B/s]\n",
      "100%|| 20.8k/20.8k [00:00<00:00, 1.10MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1sf_qQ_boL0YBW79VH4G66yRKDWAnn4Nk\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.5k [00:00<?, ?B/s]\n",
      "100%|| 19.5k/19.5k [00:00<00:00, 1.06MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ii1fFuhtdpLdtkPUIx95J7K5YE4gLmwc\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.5k [00:00<?, ?B/s]\n",
      "100%|| 20.5k/20.5k [00:00<00:00, 1.08MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MiMtCvB1QqAfGzFUUEAuRT7TP5Eq8dPw\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---06-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.9k [00:00<?, ?B/s]\n",
      "100%|| 19.9k/19.9k [00:00<00:00, 1.04MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GQoWLINz4yLZm7MAkzptupQytZeeXais\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---07-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.2k [00:00<?, ?B/s]\n",
      "100%|| 20.2k/20.2k [00:00<00:00, 1.04MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MfAIg9JF08eAoZYvgG6oYGnAgvxchqgt\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---08-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.03MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_W-TTGsPII9FpaieqFWF4pyRHMWN-3C6\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---09-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.2k [00:00<?, ?B/s]\n",
      "100%|| 20.2k/20.2k [00:00<00:00, 1.03MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1X45InFbJlO0gQRDfmkYlyZqs3lmRxtW7\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---10-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/49.2k [00:00<?, ?B/s]\n",
      "100%|| 49.2k/49.2k [00:00<00:00, 1.23MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1eTeNfJ-c8y36QCspeljRikeK4Uz-yjVd\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---11-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.2k [00:00<?, ?B/s]\n",
      "100%|| 19.2k/19.2k [00:00<00:00, 1.07MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RUZ2akVj03nuKaXAaQcpf44ozDRSOk28\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---12-2023.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.06MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1f1FdeiIbcvfq3BSntDkPXLe9OpgZM8Qt\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.1k [00:00<?, ?B/s]\n",
      "100%|| 21.1k/21.1k [00:00<00:00, 1.03MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mBPQLjo6nHgESrcjGdtUC4Z8X48Qt8SR\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.8k [00:00<?, ?B/s]\n",
      "100%|| 19.8k/19.8k [00:00<00:00, 975kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dQvVRFxbLjklFxWFG24EzYm4ckoWfvKC\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/21.3k [00:00<?, ?B/s]\n",
      "100%|| 21.3k/21.3k [00:00<00:00, 1.20MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IxH87LwFYVD4UqbpN4Hn0iZ5nsKDGC4f\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.2k [00:00<?, ?B/s]\n",
      "100%|| 20.2k/20.2k [00:00<00:00, 1.02MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1n05RkkhMQZaAMBpnAXbWXNSH24KkUG0e\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.8k [00:00<?, ?B/s]\n",
      "100%|| 20.8k/20.8k [00:00<00:00, 999kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yBPEvHZdE9KoDOOqglOKae3Hc6IUtoiR\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---06-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.1k [00:00<?, ?B/s]\n",
      "100%|| 20.1k/20.1k [00:00<00:00, 1.07MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NJ-iAAVOoGv7xx71iQLGMEMpBsfeQ48_\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---07-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.9k [00:00<?, ?B/s]\n",
      "100%|| 20.9k/20.9k [00:00<00:00, 971kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1oFzgGtIqvcnJS-F97m6LaN3Qz5hTj6d2\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---08-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.9k [00:00<?, ?B/s]\n",
      "100%|| 20.9k/20.9k [00:00<00:00, 999kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1iy8MB7L6cybJQAFvrpCOlI7jmQUCU11d\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---09-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.9k [00:00<?, ?B/s]\n",
      "100%|| 20.9k/20.9k [00:00<00:00, 1.01MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1YTXYEbpDKkqgjtNcJiHtm81GgyzKWxT6\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---10-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/64.0k [00:00<?, ?B/s]\n",
      "100%|| 64.0k/64.0k [00:00<00:00, 1.39MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1X0o1GWnTt6u5Pj-sDlaNurSNg5kqEE8v\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---11-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/18.7k [00:00<?, ?B/s]\n",
      "100%|| 18.7k/18.7k [00:00<00:00, 1.14MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NsfBsiXuTU1RovfUK0qiIdrsgnBa61T3\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---12-2023.xlsx\n",
      "\n",
      "  0%|          | 0.00/20.3k [00:00<?, ?B/s]\n",
      "100%|| 20.3k/20.3k [00:00<00:00, 1.03MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1CPfb7PUOgjVWtcHrkQelGsdBRNq2Ks9t\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---01-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.0k [00:00<?, ?B/s]\n",
      "100%|| 19.0k/19.0k [00:00<00:00, 6.65MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lnZY1HzGuDujmNIu9cvxnD8Wse5Gizjh\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---02-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/18.3k [00:00<?, ?B/s]\n",
      "100%|| 18.3k/18.3k [00:00<00:00, 974kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UXzCiuifVR3GcBQ1Wpc2OYwGmrOUxIJ-\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---03-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/19.0k [00:00<?, ?B/s]\n",
      "100%|| 19.0k/19.0k [00:00<00:00, 2.14MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qQtZKWTxTDOTLI7-3o5xckUR06yOVDwE\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---04-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/16.2k [00:00<?, ?B/s]\n",
      "100%|| 16.2k/16.2k [00:00<00:00, 866kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1VyBJVugdCUCoz3ENg6GZC_hCiBbrDvD6\n",
      "To: c:\\Users\\patar\\Documents\\superai-intern\\superaiss5-intern-vpp\\Load-data\\Data_\\-Demand---05-2024.xlsx\n",
      "\n",
      "  0%|          | 0.00/18.3k [00:00<?, ?B/s]\n",
      "100%|| 18.3k/18.3k [00:00<00:00, 877kB/s]\n",
      "Failed to retrieve file url:\n",
      "\n",
      "\tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
      "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\thttps://drive.google.com/uc?id=187xYRYUgMAFAWcWJb77R1fc-Tl2YtcP8\n",
      "\n",
      "but Gdown can't. Please check connections and permissions.\n"
     ]
    }
   ],
   "source": [
    "!gdown --folder https://drive.google.com/drive/folders/1dydbU9HlSIgGQBzYMLogDNI27uO6wga7?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABStU3J8kQ9D"
   },
   "source": [
    "## Load & Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:39:53.940968Z",
     "iopub.status.busy": "2025-07-16T17:39:53.940414Z",
     "iopub.status.idle": "2025-07-16T17:39:58.397543Z",
     "shell.execute_reply": "2025-07-16T17:39:58.396773Z",
     "shell.execute_reply.started": "2025-07-16T17:39:53.940932Z"
    },
    "id": "qldgzd415jX5",
    "outputId": "59fca88e-18c5-463f-8a8c-da75de4415fe",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 71/71 [00:02<00:00, 30.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---08-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---12-2023.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-08-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_4/-Demand---4-09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---12-2023.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---08-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-12-2023.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_ 9/-Demand--9-08-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---08-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---12-2023.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---11-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---01-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---03-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---07-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---09-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---06-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---10-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---12-2023.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---05-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---04-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---02-2024.xlsx\n",
      " Excel Processed: /kaggle/input/chula-data/Load-data/Data_/-Demand---08-2024.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|| 71/71 [00:00<00:00, 96.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-12-2023.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-01-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_ 9/-Demand--9-06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---01-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---12-2023.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---12-2023.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---01-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---12-2023.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---01-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---01-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---12-2023.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_/-Demand---02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-04-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-06-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-03-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-02-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-05-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-07-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-08-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-09-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-11-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-10-2024.csv\n",
      " CSV Processed: cleaned_data/Data_4/-Demand---4-01-2024.csv\n",
      " Wide-format saved to all_data_df.csv\n",
      " Long-format saved to all_data_timeseries.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# --------- CONFIGURATION ---------\n",
    "ROOT_XLSX_DIR = \"/kaggle/input/chula-data/Load-data\"\n",
    "CLEANED_CSV_DIR = \"cleaned_data\"\n",
    "PREPROCESSED_CSV_DIR = \"preprocessed_data\"\n",
    "FINAL_WIDE_CSV = \"all_data_df.csv\"\n",
    "FINAL_LONG_CSV = \"all_data_timeseries.csv\"\n",
    "# ---------------------------------\n",
    "\n",
    "def clean_header_and_drop_unused_rows(tmp_df):\n",
    "    tmp_df.columns = tmp_df.iloc[0]\n",
    "    tmp_df = tmp_df[1:].reset_index(drop=True)\n",
    "    if 'Date' in tmp_df.columns:\n",
    "        tmp_df = tmp_df[~pd.isna(tmp_df['Date'])]\n",
    "    return tmp_df\n",
    "\n",
    "def process_excel_file(file_info):\n",
    "    file_path, rel_path = file_info\n",
    "    try:\n",
    "        tmp_df = pd.read_excel(file_path)\n",
    "        cleaned_df = clean_header_and_drop_unused_rows(tmp_df)\n",
    "        output_path = os.path.join(CLEANED_CSV_DIR, rel_path).replace(\".xlsx\", \".csv\")\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        cleaned_df.to_csv(output_path, index=False)\n",
    "        return f\" Excel Processed: {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\" Excel Error in {file_path}: {str(e)}\"\n",
    "\n",
    "def preprocess_and_add_datetime(tmp_df, filename):\n",
    "    match = re.search(r\"(\\d{2})-(\\d{4})\", filename)\n",
    "    if not match:\n",
    "        raise ValueError(f\" Cannot extract date from filename: {filename}\")\n",
    "\n",
    "    start_month = int(match.group(1))\n",
    "    start_year = int(match.group(2))\n",
    "    tmp_df = tmp_df.reset_index(drop=True)\n",
    "\n",
    "    date_range = pd.date_range(start=datetime(start_year, start_month, 1), periods=len(tmp_df), freq='D')\n",
    "    tmp_df['Date'] = date_range\n",
    "\n",
    "    time_cols = [col for col in tmp_df.columns if col != 'Date']\n",
    "    tmp_df[time_cols] = tmp_df[time_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    return tmp_df\n",
    "\n",
    "def process_csv_file(file_info):\n",
    "    file_path, rel_path = file_info\n",
    "    try:\n",
    "        tmp_df = pd.read_csv(file_path)\n",
    "        processed_df = preprocess_and_add_datetime(tmp_df, os.path.basename(file_path))\n",
    "\n",
    "        station_name = os.path.normpath(rel_path).split(os.sep)[0]\n",
    "        processed_df.insert(0, 'station_name', station_name)\n",
    "\n",
    "        output_path = os.path.join(PREPROCESSED_CSV_DIR, rel_path)\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        processed_df.to_csv(output_path, index=False)\n",
    "        return f\" CSV Processed: {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\" CSV Error in {file_path}: {str(e)}\"\n",
    "\n",
    "def gather_files(root_dir, extension):\n",
    "    files = []\n",
    "    for subdir, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            if f.endswith(extension):\n",
    "                full = os.path.join(subdir, f)\n",
    "                rel = os.path.relpath(full, root_dir)\n",
    "                files.append((full, rel))\n",
    "    return files\n",
    "\n",
    "def concatenate_preprocessed_data(output_dir):\n",
    "    all_data = []\n",
    "    for subdir, _, files in os.walk(output_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(subdir, file))\n",
    "                    all_data.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\" Failed to read {file}: {e}\")\n",
    "    return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()\n",
    "\n",
    "def convert_to_timeseries_long_format(df):\n",
    "    time_columns = [col for col in df.columns if re.match(r\"^\\d{1,2}:\\d{2}$\", str(col))]\n",
    "    long_df = df.melt(id_vars=['station_name', 'Date'], value_vars=time_columns,\n",
    "                      var_name='Time', value_name='Electricity(kW)')\n",
    "    long_df['Date'] = pd.to_datetime(long_df['Date'].astype(str) + ' ' + long_df['Time'])\n",
    "    long_df.drop(columns=['Time'], inplace=True)\n",
    "    long_df.sort_values(by=['station_name', 'Date'], inplace=True)\n",
    "    return long_df\n",
    "\n",
    "# ----------- MAIN EXECUTION FLOW -----------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Clean Excel files to CSV\n",
    "    xlsx_files = gather_files(ROOT_XLSX_DIR, \".xlsx\")\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap_unordered(process_excel_file, xlsx_files), total=len(xlsx_files)))\n",
    "    for res in results:\n",
    "        print(res)\n",
    "\n",
    "    # Step 2: Preprocess cleaned CSVs\n",
    "    csv_files = gather_files(CLEANED_CSV_DIR, \".csv\")\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap_unordered(process_csv_file, csv_files), total=len(csv_files)))\n",
    "    for res in results:\n",
    "        print(res)\n",
    "\n",
    "    # Step 3: Concatenate all preprocessed CSVs\n",
    "    all_data_df = concatenate_preprocessed_data(PREPROCESSED_CSV_DIR)\n",
    "    if not all_data_df.empty:\n",
    "        all_data_df.to_csv(FINAL_WIDE_CSV, index=False)\n",
    "        print(f\" Wide-format saved to {FINAL_WIDE_CSV}\")\n",
    "\n",
    "        # Step 4: Convert to long time series format\n",
    "        long_df = convert_to_timeseries_long_format(all_data_df)\n",
    "        long_df.to_csv(FINAL_LONG_CSV, index=False)\n",
    "        print(f\" Long-format saved to {FINAL_LONG_CSV}\")\n",
    "    else:\n",
    "        print(\" No data found for concatenation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xij_U2YS-Bwu"
   },
   "source": [
    "## Define Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:40:00.178102Z",
     "iopub.status.busy": "2025-07-16T17:40:00.177322Z",
     "iopub.status.idle": "2025-07-16T17:40:00.183025Z",
     "shell.execute_reply": "2025-07-16T17:40:00.182306Z",
     "shell.execute_reply.started": "2025-07-16T17:40:00.178070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "station_weights_df = pd.DataFrame({\n",
    "    \"station_name\": [\n",
    "        \"Data_\",\n",
    "        \"Data_ 9\",\n",
    "        \"Data_\",\n",
    "        \"Data_\",\n",
    "        \"Data_\",\n",
    "        \"Data_4\",\n",
    "    ],\n",
    "    \"normalized_reverse_weight\": [\n",
    "        1.000000,\n",
    "        1.000000,\n",
    "        1.000000,        1.002786,\n",
    "        1.002786,\n",
    "        1.094225,\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbmXMa55si81"
   },
   "source": [
    "## Experiment [Clean Data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:40:01.878700Z",
     "iopub.status.busy": "2025-07-16T17:40:01.878140Z",
     "iopub.status.idle": "2025-07-16T17:40:01.884573Z",
     "shell.execute_reply": "2025-07-16T17:40:01.883918Z",
     "shell.execute_reply.started": "2025-07-16T17:40:01.878677Z"
    },
    "id": "5BDUFvTjzGI7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(long_df):\n",
    "    long_df.loc[long_df['Electricity(kW)'] < 0, 'Electricity(kW)'] = 0\n",
    "    return long_df\n",
    "# long_df_tmp = preprocess(long_df_new)\n",
    "long_df = preprocess(long_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:40:03.434597Z",
     "iopub.status.busy": "2025-07-16T17:40:03.434331Z",
     "iopub.status.idle": "2025-07-16T17:40:03.458932Z",
     "shell.execute_reply": "2025-07-16T17:40:03.458088Z",
     "shell.execute_reply.started": "2025-07-16T17:40:03.434574Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data_', 'Data_ 9', 'Data_4',\n",
       "       'Data_', 'Data_',\n",
       "       'Data_'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df['station_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rg9u9_6Xt8bK"
   },
   "source": [
    "## Split train,valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:40:05.388333Z",
     "iopub.status.busy": "2025-07-16T17:40:05.387644Z",
     "iopub.status.idle": "2025-07-16T17:40:05.469989Z",
     "shell.execute_reply": "2025-07-16T17:40:05.469170Z",
     "shell.execute_reply.started": "2025-07-16T17:40:05.388309Z"
    },
    "id": "AtDIorByqvOn",
    "outputId": "4dc58f30-8668-4c99-d584-e7c6be639763",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_train_test_data(long_df,long_df_new):\n",
    "    # Define ratios\n",
    "    train_ratio = 0.8\n",
    "    test_ratio = 0.2  # Optional, just for clarity (1 - train_ratio)\n",
    "    \n",
    "    # Create empty lists to collect per-station splits\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    # Split per station\n",
    "    for station, station_df in long_df_new.groupby('station_name'):\n",
    "        station_df = station_df.sort_values('Date')\n",
    "        n = len(station_df)\n",
    "    \n",
    "        train_end = int(n * train_ratio)\n",
    "    \n",
    "        train_list.append(station_df.iloc[:train_end])\n",
    "        test_list.append(station_df.iloc[train_end:])\n",
    "    \n",
    "    # Combine all stations back into global sets\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    # Create empty lists to collect per-station splits\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    for station, station_df in long_df.groupby('station_name'):\n",
    "        station_df = station_df.sort_values('Date')\n",
    "        n = len(station_df)\n",
    "    \n",
    "        train_end = int(n * train_ratio)\n",
    "    \n",
    "        train_list.append(station_df.iloc[:train_end])\n",
    "        test_list.append(station_df.iloc[train_end:])\n",
    "    \n",
    "    test_df_new = pd.concat(test_list).reset_index(drop=True)\n",
    "    \n",
    "    return train_df,test_df_new\n",
    "train_df,test_df = split_train_test_data(long_df,long_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T17:40:08.130361Z",
     "iopub.status.busy": "2025-07-16T17:40:08.129759Z",
     "iopub.status.idle": "2025-07-16T17:40:08.134234Z",
     "shell.execute_reply": "2025-07-16T17:40:08.133485Z",
     "shell.execute_reply.started": "2025-07-16T17:40:08.130338Z"
    },
    "id": "O-ztRs2H6twN",
    "outputId": "4abec5f5-935e-454d-8ac9-db9bc07f6576",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "locations = {\n",
    "    \"Data_\": (13.73624, 100.52995), #Station_name, latitude,longitude\n",
    "    \"Data_4\": (13.73260, 100.53177),\n",
    "    \"Data_ 9\": (13.73380, 100.53045),\n",
    "    \"Data_\": (13.73684, 100.52852),\n",
    "    \"Data_\": (13.73800, 100.52905),\n",
    "    \"Data_\": (13.73723, 100.53015),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:12:22.593546Z",
     "iopub.status.busy": "2025-07-16T09:12:22.593011Z",
     "iopub.status.idle": "2025-07-16T09:12:22.610873Z",
     "shell.execute_reply": "2025-07-16T09:12:22.610299Z",
     "shell.execute_reply.started": "2025-07-16T09:12:22.593525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data_', 'Data_ 9', 'Data_4',\n",
       "       'Data_', 'Data_',\n",
       "       'Data_'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['station_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:21:56.148488Z",
     "iopub.status.busy": "2025-07-16T18:21:56.147699Z",
     "iopub.status.idle": "2025-07-16T18:26:25.996813Z",
     "shell.execute_reply": "2025-07-16T18:26:25.995931Z",
     "shell.execute_reply.started": "2025-07-16T18:21:56.148461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094a6262ae62439eb03d716d39d0233a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 01:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01  Avg Loss: 21378.1381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7042a450f34d73830184666ed9544f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 02:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02  Avg Loss: 21248.3226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8fd6a6da541cc9e30b21dd9353645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 03:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03  Avg Loss: 21109.9218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365656142f4146bcac293531b9b8ae57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 04:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04  Avg Loss: 21036.1655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a074581bb5a46d88ae3b8df2f3f3bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 05:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05  Avg Loss: 21007.6627\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal import ASTGCN\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Prepare device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Graph setup\n",
    "locations = {\n",
    "    \"Data_\": (13.73624, 100.52995),\n",
    "    \"Data_4\": (13.73260, 100.53177),\n",
    "    \"Data_ 9\": (13.73380, 100.53045),\n",
    "    \"Data_\": (13.73684, 100.52852),\n",
    "    \"Data_\": (13.73800, 100.52905),\n",
    "    \"Data_\": (13.73723, 100.53015),\n",
    "}\n",
    "station_names = list(locations.keys())\n",
    "num_nodes = len(station_names)\n",
    "\n",
    "# fully connected edges (i != j)\n",
    "edge_index = torch.tensor(\n",
    "    [[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j],\n",
    "    dtype=torch.long,\n",
    ").t().contiguous().to(device)\n",
    "\n",
    "# 3. Pivot helper\n",
    "def pivot_to_tensor(df, seq_len):\n",
    "    df_pv = df.pivot(index='Date', columns='station_name', values='Electricity(kW)')\n",
    "    df_pv = df_pv[station_names].fillna(0.)\n",
    "    windows = []\n",
    "    for i in range(len(df_pv) - seq_len + 1):\n",
    "        win = df_pv.iloc[i:i+seq_len].values  # (seq_len, N)\n",
    "        windows.append(win.T)                 # (N, seq_len)\n",
    "    arr = np.stack(windows, axis=0)          # (T, N, seq_len)\n",
    "    return torch.tensor(arr, dtype=torch.float)\n",
    "\n",
    "# 4. Prepare data\n",
    "len_input = 96\n",
    "pred_len  = 96\n",
    "\n",
    "X = pivot_to_tensor(train_df, len_input + pred_len)\n",
    "X_in  = X[:, :, :len_input]\n",
    "X_out = X[:, :, len_input:]\n",
    "\n",
    "class TemporalDataset(Dataset):\n",
    "    def __init__(self, X_i, X_o):\n",
    "        self.X_i, self.X_o = X_i, X_o\n",
    "    def __len__(self):\n",
    "        return len(self.X_i)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_i[idx], self.X_o[idx]\n",
    "\n",
    "loader = DataLoader(TemporalDataset(X_in, X_out), batch_size=512, shuffle=True)\n",
    "\n",
    "# 5. Model definition\n",
    "class ASTGCN_V2(nn.Module):\n",
    "    def __init__(self, num_nodes, **kwargs):\n",
    "        super().__init__()\n",
    "        self.astgcn = ASTGCN(**kwargs)\n",
    "        self.node_emb1 = nn.Parameter(torch.randn(num_nodes, 10))\n",
    "        self.node_emb2 = nn.Parameter(torch.randn(10, num_nodes))\n",
    "\n",
    "    def forward(self, x, edge_index=None):\n",
    "        A_int = F.relu(self.node_emb1 @ self.node_emb2)  # (N, N)\n",
    "        A_adp = F.softmax(A_int, dim=1)\n",
    "        ei_adp, _ = dense_to_sparse(A_adp)\n",
    "        out = self.astgcn(x, ei_adp.to(x.device))\n",
    "        return F.relu(out)\n",
    "\n",
    "config = {\n",
    "    \"nb_block\": 2,\n",
    "    \"in_channels\": 1,\n",
    "    \"K\": 2,\n",
    "    \"nb_chev_filter\": 64,\n",
    "    \"nb_time_filter\": 64,\n",
    "    \"time_strides\": 1,\n",
    "    \"num_for_predict\": pred_len,\n",
    "    \"len_input\": len_input,\n",
    "    \"num_of_vertices\": num_nodes,\n",
    "    \"normalization\": \"sym\",\n",
    "    \"bias\": True,\n",
    "}\n",
    "max_lr = 1e-2\n",
    "model     = ASTGCN_V2(num_nodes=num_nodes, **config).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=max_lr,\n",
    "    steps_per_epoch=len(loader),\n",
    "    epochs=5,\n",
    "    pct_start=0.3,\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n",
    "# 6. Training\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    total_loss = 0.0\n",
    "    for X_batch, Y_batch in tqdm(loader, desc=f\"Epoch {epoch+1:02d}\"):\n",
    "        Xb = X_batch.unsqueeze(2).to(device)  # [B, N, 1, len_input]\n",
    "        Yb = Y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=\"cuda\"):  # now uses torch.amp.autocast\n",
    "            preds = model(Xb, edge_index)\n",
    "            loss  = criterion(preds, Yb)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        scaler.step(optimizer)  # this performs optimizer.step()\n",
    "        scaler.update()\n",
    "        scheduler.step()        # now correctly after optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1:02d}  Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ASTGCNWrapper(nn.Module):\n",
    "    def __init__(self, model, edge_index):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x, self.edge_index)\n",
    "from torchview import draw_graph\n",
    "\n",
    "# Wrap the model with fixed edge_index\n",
    "wrapped_model = ASTGCNWrapper(model, edge_index)\n",
    "\n",
    "# Provide the correct input shape: (batch_size, num_nodes, 1, len_input)\n",
    "draw_graph(\n",
    "    wrapped_model,\n",
    "    input_size=(1, num_nodes, 1, len_input),\n",
    "    expand_nested=True,\n",
    "    roll=True,\n",
    "    show_shapes=True,\n",
    ").visual_graph.render(\"astgcn_graph_v2.0\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:27:28.274248Z",
     "iopub.status.busy": "2025-07-16T18:27:28.273836Z",
     "iopub.status.idle": "2025-07-16T18:27:52.908705Z",
     "shell.execute_reply": "2025-07-16T18:27:52.907942Z",
     "shell.execute_reply.started": "2025-07-16T18:27:28.274212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea380791060f4f36a5095d8185792062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE (firststep, dropping 570 rows with no pred): 88.9843\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Pivot and concatenate train+test\n",
    "df_all = pd.concat([train_df, test_df], ignore_index=True)\n",
    "pivot = (df_all\n",
    "         .pivot(index='Date', columns='station_name', values='Electricity(kW)')\n",
    "         .reindex(columns=station_names)      # ensure correct station order\n",
    "         .fillna(0.0))\n",
    "dates = pivot.index\n",
    "T = len(dates)\n",
    "\n",
    "# 2. Build every possible sliding window of length `len_input`\n",
    "prediction_length = 96\n",
    "max_start = T - len_input - prediction_length + 1  # total windows\n",
    "windows = []\n",
    "for t0 in range(max_start):\n",
    "    arr = pivot.iloc[t0:t0+len_input].values       # (len_input, N)\n",
    "    windows.append(arr.T)                          #  (N, len_input)\n",
    "X_all = np.stack(windows, axis=0)                  # (W, N, len_input)\n",
    "X_all = torch.from_numpy(X_all).float().unsqueeze(2)  # (W, N, 1, len_input)\n",
    "\n",
    "# 3. Batch through the model in eval mode\n",
    "batch_size = 512\n",
    "loader = DataLoader(TensorDataset(X_all), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for (Xb,) in tqdm(loader,desc=\"batch\"):\n",
    "        Xb = Xb.to(device)\n",
    "        yb = model(Xb, edge_index)               #  (B, N, prediction_length)\n",
    "        preds.append(yb.cpu().numpy())\n",
    "preds = np.concatenate(preds, axis=0)            # (W, N, pred_len)\n",
    "\n",
    "# 4. Take only the *first-step* forecast (you can slice other horizons similarly)\n",
    "first_step = preds[:, :, 0]                      # (W, N)\n",
    "\n",
    "# 5. Build a long DataFrame of all predictions\n",
    "#    window w predicts for date = dates[w + len_input]\n",
    "pred_dates = dates[len_input : len_input + first_step.shape[0]]\n",
    "records = []\n",
    "for w, pd_dt in enumerate(pred_dates):\n",
    "    for i, station in enumerate(station_names):\n",
    "        records.append((pd_dt, station, first_step[w, i]))\n",
    "df_preds = pd.DataFrame(records, columns=['Date','station_name','Predicted(kW)'])\n",
    "\n",
    "# 6. Merge with test_df (this yields exactly len(test_df)=40 839 rows)\n",
    "df_merged = (test_df\n",
    "             .merge(df_preds, on=['Date','station_name'], how='left')\n",
    "             .sort_values(['Date','station_name'])\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# after your merge:\n",
    "df_eval = df_merged.dropna(subset=['Predicted(kW)']).copy()\n",
    "\n",
    "# compute MAE only on the nonNaN rows\n",
    "mae = mean_absolute_error(\n",
    "    df_eval['Electricity(kW)'].values,\n",
    "    df_eval['Predicted(kW)'].values\n",
    ")\n",
    "print(f\"Test MAE (firststep, dropping {len(df_merged) - len(df_eval)} rows with no pred): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:27:52.910033Z",
     "iopub.status.busy": "2025-07-16T18:27:52.909738Z",
     "iopub.status.idle": "2025-07-16T18:27:52.924607Z",
     "shell.execute_reply": "2025-07-16T18:27:52.924031Z",
     "shell.execute_reply.started": "2025-07-16T18:27:52.910013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAPE (weighted): 0.9659 or 96.59%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Merge weights into evaluation DataFrame\n",
    "df_eval = df_eval.merge(station_weights_df, on='station_name', how='left')\n",
    "\n",
    "# Compute weighted absolute error\n",
    "df_eval['abs_error'] = np.abs(df_eval['Electricity(kW)'] - df_eval['Predicted(kW)'])\n",
    "df_eval['weighted_abs_error'] = df_eval['abs_error'] * df_eval['normalized_reverse_weight']\n",
    "\n",
    "# Compute weighted actual value\n",
    "df_eval['weighted_actual'] = df_eval['Electricity(kW)'] * df_eval['normalized_reverse_weight']\n",
    "\n",
    "# Calculate WAPE\n",
    "wape = df_eval['weighted_abs_error'].sum() / df_eval['weighted_actual'].sum()\n",
    "print(f\"WAPE (weighted): {wape:.4f} or {wape*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T09:41:09.404521Z",
     "iopub.status.busy": "2025-07-16T09:41:09.404271Z",
     "iopub.status.idle": "2025-07-16T09:41:09.740994Z",
     "shell.execute_reply": "2025-07-16T09:41:09.740245Z",
     "shell.execute_reply.started": "2025-07-16T09:41:09.404504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_eval.to_csv(\"df_eval.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize runtime & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:30:14.476025Z",
     "iopub.status.busy": "2025-07-16T18:30:14.475418Z",
     "iopub.status.idle": "2025-07-16T18:30:39.487661Z",
     "shell.execute_reply": "2025-07-16T18:30:39.486883Z",
     "shell.execute_reply.started": "2025-07-16T18:30:14.476000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:5331: UserWarning: Exporting aten::index operator with indices of type Byte. Only 1-D indices are supported. In any other case, this will produce an incorrect ONNX graph.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/onnx/symbolic_opset9.py:5383: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model saved to astgcn_v2.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# assume `model` is your trained ASTGCN_V2 on CUDA or CPU\n",
    "model.eval()\n",
    "model.to(\"cpu\")  # ONNX export is easiest on CPU\n",
    "\n",
    "# example dummy input matching your train-time shape: [B, N, 1, len_input]\n",
    "# here B=1 for tracing, N=num_nodes, len_input=96\n",
    "dummy_input = torch.randn(1, num_nodes, 1, len_input, dtype=torch.float)\n",
    "\n",
    "# export\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (dummy_input, edge_index.cpu()),             # model inputs\n",
    "    \"astgcn_v2.onnx\",                             # output file\n",
    "    export_params=True,                           # store weights\n",
    "    opset_version=14,                             # recommended >= 12\n",
    "    do_constant_folding=True,                     # fuse constants\n",
    "    input_names=[\"input\", \"edge_index\"],          \n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 3: \"seq_len\"}, # batch & time dims dynamic\n",
    "        \"output\": {0: \"batch_size\", 2: \"pred_len\"},\n",
    "    }\n",
    ")\n",
    "print(\"ONNX model saved to astgcn_v2.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:31:40.471782Z",
     "iopub.status.busy": "2025-07-16T18:31:40.471011Z",
     "iopub.status.idle": "2025-07-16T18:31:45.127057Z",
     "shell.execute_reply": "2025-07-16T18:31:45.125967Z",
     "shell.execute_reply.started": "2025-07-16T18:31:40.471757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnxruntime-tools in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (1.18.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (1.26.4)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (15.0.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (9.0.0)\n",
      "Requirement already satisfied: py3nvml in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (0.2.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime-tools) (25.0)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (6.31.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->onnxruntime-tools) (2.4.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime-tools) (10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxruntime-tools) (4.14.0)\n",
      "Requirement already satisfied: xmltodict in /usr/local/lib/python3.11/dist-packages (from py3nvml->onnxruntime-tools) (0.14.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->onnxruntime-tools) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->onnxruntime-tools) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->onnxruntime-tools) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->onnxruntime-tools) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->onnxruntime-tools) (2024.2.0)\n",
      "Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime-tools onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T18:51:17.248565Z",
     "iopub.status.busy": "2025-07-16T18:51:17.248296Z",
     "iopub.status.idle": "2025-07-16T18:52:58.856234Z",
     "shell.execute_reply": "2025-07-16T18:52:58.855609Z",
     "shell.execute_reply.started": "2025-07-16T18:51:17.248547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Raw ONNX exported to astgcn_cpu.onnx\n",
      " Optimization skipped: invalid literal for int() with base 10: 'unk__0'\n",
      " Raw ONNX exported to astgcn_gpu.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from onnxruntime_tools import optimizer\n",
    "from onnxruntime_tools.transformers.onnx_model_bert import BertOptimizationOptions\n",
    "\n",
    "def export_to_onnx(\n",
    "    model: torch.nn.Module,\n",
    "    edge_index: torch.Tensor,\n",
    "    output_path: str = \"model.onnx\",\n",
    "    optimized_path: str = None,\n",
    "    len_input: int = 96,\n",
    "    device: str = \"cpu\",\n",
    "    opset_version: int = 14,\n",
    "    do_optimize: bool = True,\n",
    "    model_type: str = \"bert\",\n",
    "    num_heads: int = 1,\n",
    "    num_nodes: int = 6,\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports a PyTorch ASTGCN_V2 model (with dynamic batch & seq dims) to ONNX,\n",
    "    then optionally runs ONNX Runtime optimizations.\n",
    "\n",
    "    Args:\n",
    "        model: the trained ASTGCN_V2 instance.\n",
    "        edge_index: Tensor of shape [2, E] describing your graph.\n",
    "        output_path: where to write the raw ONNX file.\n",
    "        optimized_path: if provided and do_optimize=True, saves optimized model here.\n",
    "                        if None, overwrites output_path.\n",
    "        len_input: the sequence length used at export time.\n",
    "        device: \"cpu\" or \"cuda\"  where to place the model/dummy for export.\n",
    "        opset_version: ONNX opset to target.\n",
    "        do_optimize: whether to run ONNX Runtime graph optimizations.\n",
    "        model_type: passed to optimizer.optimize_model (default \"bert\").\n",
    "        num_heads: dummy heads count for optimizer; not critical for ASTGCN.\n",
    "\n",
    "    Returns:\n",
    "        path to the final ONNX file (optimized_path or output_path).\n",
    "    \"\"\"\n",
    "    # 1) Prepare model & dummy\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    dummy_input = torch.randn(1,num_nodes, 1, len_input, device=device)\n",
    "    ei = edge_index.to(device)\n",
    "\n",
    "    # 2) Export to ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        (dummy_input, ei),\n",
    "        output_path,\n",
    "        export_params=True,\n",
    "        opset_version=opset_version,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\", \"edge_index\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\", 3: \"seq_len\"},\n",
    "            \"output\": {0: \"batch_size\", 2: \"pred_len\"},\n",
    "        },\n",
    "    )\n",
    "    print(f\" Raw ONNX exported to {output_path}\")\n",
    "\n",
    "    final_path = output_path\n",
    "\n",
    "    # 3) Optional optimization\n",
    "    if do_optimize:\n",
    "        optimized_path = optimized_path or output_path\n",
    "        try:\n",
    "            opt_opts = BertOptimizationOptions(model_type)\n",
    "            opt_model = optimizer.optimize_model(\n",
    "                output_path,\n",
    "                model_type=model_type,\n",
    "                num_heads=num_heads,\n",
    "                optimization_options=opt_opts,\n",
    "            )\n",
    "            opt_model.save_model_to_file(optimized_path)\n",
    "            final_path = optimized_path\n",
    "            print(f\" Optimized ONNX saved to {optimized_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Optimization skipped: {e}\")\n",
    "\n",
    "    return final_path\n",
    "# Export for CPU (default), with optimization:\n",
    "onnx_path = export_to_onnx(\n",
    "    model,\n",
    "    edge_index,\n",
    "    output_path=\"astgcn_cpu.onnx\",\n",
    "    optimized_path=\"astgcn_cpu_opt.onnx\",\n",
    "    len_input=96,\n",
    "    device=\"cpu\",\n",
    "    do_optimize=True,\n",
    "    num_nodes = num_nodes\n",
    ")\n",
    "\n",
    "# Export for GPU (with CUDAExecutionProvider support), without optimization:\n",
    "onnx_path_gpu = export_to_onnx(\n",
    "    model,\n",
    "    edge_index,\n",
    "    output_path=\"astgcn_gpu.onnx\",\n",
    "    optimized_path=None,\n",
    "    len_input=96,\n",
    "    device=\"cuda\",\n",
    "    do_optimize=False,\n",
    "    num_nodes = num_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T19:14:30.895811Z",
     "iopub.status.busy": "2025-07-16T19:14:30.895565Z",
     "iopub.status.idle": "2025-07-16T19:15:02.763934Z",
     "shell.execute_reply": "2025-07-16T19:15:02.763276Z",
     "shell.execute_reply.started": "2025-07-16T19:14:30.895793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[12799.7539,     0.0000,  5685.4536,  ..., 14815.2021,\n",
       "          15516.9492, 12834.8281],\n",
       "         [12846.3926,     0.0000,  5713.2607,  ..., 14879.3564,\n",
       "          15589.9453, 12883.4619],\n",
       "         [12809.1348,     0.0000,  5696.7539,  ..., 14831.0449,\n",
       "          15529.9922, 12845.7881],\n",
       "         [12799.8408,     0.0000,  5685.4819,  ..., 14815.3086,\n",
       "          15517.1387, 12834.9121],\n",
       "         [12794.8584,     0.0000,  5685.0708,  ..., 14810.7051,\n",
       "          15509.5195, 12830.2715],\n",
       "         [12799.6885,     0.0000,  5685.4453,  ..., 14815.1416,\n",
       "          15516.8145, 12834.7617]],\n",
       "\n",
       "        [[12799.7783,     0.0000,  5685.4624,  ..., 14815.2324,\n",
       "          15516.9619, 12834.8525],\n",
       "         [12846.3350,     0.0000,  5713.2412,  ..., 14879.2998,\n",
       "          15589.8691, 12883.4111],\n",
       "         [12809.0234,     0.0000,  5696.7124,  ..., 14830.9219,\n",
       "          15529.8594, 12845.6777],\n",
       "         [12799.0996,     0.0000,  5685.1938,  ..., 14814.4795,\n",
       "          15516.2998, 12834.1787],\n",
       "         [12794.8740,     0.0000,  5685.0737,  ..., 14810.7236,\n",
       "          15509.5547, 12830.2930],\n",
       "         [12799.7861,     0.0000,  5685.4775,  ..., 14815.2471,\n",
       "          15516.9600, 12834.8604]],\n",
       "\n",
       "        [[12799.7783,     0.0000,  5685.4624,  ..., 14815.2344,\n",
       "          15516.9570, 12834.8555],\n",
       "         [12846.3223,     0.0000,  5713.2334,  ..., 14879.2764,\n",
       "          15589.8691, 12883.3906],\n",
       "         [12809.2051,     0.0000,  5696.7773,  ..., 14831.1211,\n",
       "          15530.0752, 12845.8594],\n",
       "         [12800.1084,     0.0000,  5685.5977,  ..., 14815.5986,\n",
       "          15517.3438, 12835.1729],\n",
       "         [12794.9346,     0.0000,  5685.0874,  ..., 14810.7783,\n",
       "          15509.7246, 12830.3418],\n",
       "         [12799.7158,     0.0000,  5685.4585,  ..., 14815.1689,\n",
       "          15516.9014, 12834.7920]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[12799.7734,     0.0000,  5685.4580,  ..., 14815.2236,\n",
       "          15516.9678, 12834.8428],\n",
       "         [12846.4004,     0.0000,  5713.2637,  ..., 14879.3672,\n",
       "          15589.9648, 12883.4727],\n",
       "         [12809.2539,     0.0000,  5696.7783,  ..., 14831.1904,\n",
       "          15530.1768, 12845.9053],\n",
       "         [12799.7900,     0.0000,  5685.4531,  ..., 14815.2070,\n",
       "          15517.1348, 12834.8516],\n",
       "         [12794.7246,     0.0000,  5685.0044,  ..., 14810.5479,\n",
       "          15509.4541, 12830.1250],\n",
       "         [12799.6982,     0.0000,  5685.4497,  ..., 14815.1484,\n",
       "          15516.8652, 12834.7725]],\n",
       "\n",
       "        [[12799.8467,     0.0000,  5685.4800,  ..., 14815.3086,\n",
       "          15517.0674, 12834.9199],\n",
       "         [12846.3682,     0.0000,  5713.2524,  ..., 14879.3340,\n",
       "          15589.9199, 12883.4424],\n",
       "         [12809.1553,     0.0000,  5696.7563,  ..., 14831.0635,\n",
       "          15530.0449, 12845.8145],\n",
       "         [12799.8643,     0.0000,  5685.5059,  ..., 14815.3320,\n",
       "          15517.1074, 12834.9326],\n",
       "         [12794.7178,     0.0000,  5684.9941,  ..., 14810.5449,\n",
       "          15509.4824, 12830.1211],\n",
       "         [12799.7471,     0.0000,  5685.4624,  ..., 14815.2100,\n",
       "          15516.9238, 12834.8223]],\n",
       "\n",
       "        [[12799.7861,     0.0000,  5685.4697,  ..., 14815.2412,\n",
       "          15516.9844, 12834.8613],\n",
       "         [12846.3350,     0.0000,  5713.2388,  ..., 14879.2900,\n",
       "          15589.8721, 12883.4053],\n",
       "         [12809.0811,     0.0000,  5696.7241,  ..., 14830.9932,\n",
       "          15529.9961, 12845.7373],\n",
       "         [12799.6055,     0.0000,  5685.3809,  ..., 14815.0518,\n",
       "          15516.9561, 12834.6699],\n",
       "         [12794.8086,     0.0000,  5685.0415,  ..., 14810.6475,\n",
       "          15509.4971, 12830.2080],\n",
       "         [12799.7295,     0.0000,  5685.4604,  ..., 14815.1904,\n",
       "          15516.8760, 12834.8047]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "class InferenceModel:\n",
    "    def __init__(self, onnx_path=\"astgcn_v2.onnx\", device=\"cpu\"):\n",
    "        providers = ([\"CUDAExecutionProvider\",\"CPUExecutionProvider\"]\n",
    "                     if device.startswith(\"cuda\") else [\"CPUExecutionProvider\"])\n",
    "        self.sess = ort.InferenceSession(onnx_path, providers=providers)\n",
    "\n",
    "        # Inspect the ONNX inputs\n",
    "        inputs = self.sess.get_inputs()\n",
    "        names = [inp.name for inp in inputs]\n",
    "        if len(names) == 2:\n",
    "            # graph expects [X, edge_index]\n",
    "            self.input_name, self.edge_name = names\n",
    "            self.need_edge = True\n",
    "        elif len(names) == 1:\n",
    "            # graph only expects [X], edge_index is built-in\n",
    "            self.input_name = names[0]\n",
    "            self.edge_name = None\n",
    "            self.need_edge = False\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unexpected number of inputs in ONNX model: {len(names)}\")\n",
    "\n",
    "        self.output_name = self.sess.get_outputs()[0].name\n",
    "\n",
    "    def forecast(self, X: torch.Tensor, edge_index: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        X: [B, N, 1, seq_len]\n",
    "        edge_index: [2, E] (only required if the ONNX session expects it)\n",
    "        \"\"\"\n",
    "        Xn = X.cpu().numpy().astype(np.float32)\n",
    "        feed = {self.input_name: Xn}\n",
    "\n",
    "        if self.need_edge:\n",
    "            if edge_index is None:\n",
    "                raise ValueError(\"This model requires edge_index, but none was given.\")\n",
    "            En = edge_index.cpu().numpy().astype(np.int64)\n",
    "            feed[self.edge_name] = En\n",
    "\n",
    "        out = self.sess.run([self.output_name], feed)[0]\n",
    "        return torch.from_numpy(out)\n",
    "\n",
    "# --- Example usage ---\n",
    "\n",
    "# Case 1: ONNX with two inputs\n",
    "inf = InferenceModel(\"astgcn_cpu.onnx\", device=\"cpu\")\n",
    "X_test = torch.randn(8, num_nodes, 1, len_input)\n",
    "preds = inf.forecast(X_test, edge_index)                # must pass edge_index\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T19:11:50.343770Z",
     "iopub.status.busy": "2025-07-16T19:11:50.343293Z",
     "iopub.status.idle": "2025-07-16T19:11:50.348265Z",
     "shell.execute_reply": "2025-07-16T19:11:50.347646Z",
     "shell.execute_reply.started": "2025-07-16T19:11:50.343749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T19:16:34.001781Z",
     "iopub.status.busy": "2025-07-16T19:16:34.001096Z",
     "iopub.status.idle": "2025-07-16T19:16:34.041200Z",
     "shell.execute_reply": "2025-07-16T19:16:34.040573Z",
     "shell.execute_reply.started": "2025-07-16T19:16:34.001757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.4 ms, sys: 0 ns, total: 71.4 ms\n",
      "Wall time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = torch.randn(1, num_nodes, 1, len_input)\n",
    "preds = inf.forecast(X_test, edge_index)                # must pass edge_index\n",
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T19:35:20.394760Z",
     "iopub.status.busy": "2025-07-16T19:35:20.394203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (reuse your existing InferenceModel instance `inf` and `edge_index`, plus num_nodes, len_input)\n",
    "\n",
    "process = psutil.Process()\n",
    "batch_sizes = [10**i for i in range(11)]  # [2, 4, 8, , 1024]\n",
    "\n",
    "records = []\n",
    "for b in batch_sizes:\n",
    "    X_test = torch.randn(b, num_nodes, 1, len_input)\n",
    "\n",
    "    # Reset peak memory if on GPU\n",
    "    use_cuda = torch.cuda.is_available() and inf.sess.get_providers()[0].startswith(\"CUDA\")\n",
    "    if use_cuda:\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    # Memory before\n",
    "    mem_before = torch.cuda.max_memory_allocated() if use_cuda else process.memory_info().rss\n",
    "\n",
    "    # Time the inference\n",
    "    start = time.perf_counter()\n",
    "    _ = inf.forecast(X_test, edge_index if inf.need_edge else None)\n",
    "    if use_cuda:\n",
    "        torch.cuda.synchronize()\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    # Memory after / peak\n",
    "    mem_after = torch.cuda.max_memory_allocated() if use_cuda else process.memory_info().rss\n",
    "\n",
    "    records.append({\n",
    "        \"batch_size\": b,\n",
    "        \"time_ms\": (end - start) * 1000,\n",
    "        \"mem_mb\": (mem_after - mem_before) / (1024**2),\n",
    "    })\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Plot latency\n",
    "plt.figure()\n",
    "plt.plot(df[\"batch_size\"], df[\"time_ms\"], marker='o')\n",
    "plt.xscale('log', base=2)\n",
    "plt.xlabel(\"Batch Size (log2 scale)\")\n",
    "plt.ylabel(\"Inference Time (ms)\")\n",
    "plt.title(\"Latency vs Batch Size\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot memory usage\n",
    "plt.figure()\n",
    "plt.plot(df[\"batch_size\"], df[\"mem_mb\"], marker='o')\n",
    "plt.xscale('log', base=2)\n",
    "plt.xlabel(\"Batch Size (log2 scale)\")\n",
    "plt.ylabel(\" Memory (MB)\")\n",
    "plt.title(\"Memory  vs Batch Size\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-16T19:12:13.202997Z",
     "iopub.status.busy": "2025-07-16T19:12:13.202679Z",
     "iopub.status.idle": "2025-07-16T19:12:13.207851Z",
     "shell.execute_reply": "2025-07-16T19:12:13.207201Z",
     "shell.execute_reply.started": "2025-07-16T19:12:13.202974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 96])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7869354,
     "sourceId": 12473148,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7878406,
     "sourceId": 12485430,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "superai-intern-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
